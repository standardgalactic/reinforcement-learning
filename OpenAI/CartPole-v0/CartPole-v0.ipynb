{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import sys\n",
    "import numpy as np\n",
    "import random as rn\n",
    "import cv2\n",
    "import time\n",
    "import functools\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "from agents.DDQN import *\n",
    "from IPython import display\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "%matplotlib inline\n",
    "\n",
    "np.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 789325\n",
    "\n",
    "rn.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_environment(envName=\"CartPole-v0\", seed=None):\n",
    "    env = gym.make(envName)        \n",
    "    if seed is not None:\n",
    "        env.seed(seed)    \n",
    "    \n",
    "    return env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show Environment information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actions:  2\n",
      "Size of state: 4\n"
     ]
    }
   ],
   "source": [
    "env = build_environment(seed=SEED)\n",
    "\n",
    "# size of each action\n",
    "action_size = env.action_space.n\n",
    "print('Actions: ', action_size)\n",
    "if hasattr(env.env, 'get_action_meanings'):\n",
    "    print(env.env.get_action_meanings())\n",
    "\n",
    "# examine the state space \n",
    "states = env.observation_space.shape\n",
    "state_size = states[0]\n",
    "print('Size of state:', state_size)\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_agent(pre_trained=None):\n",
    "    return DDQNAgent(state_size,\n",
    "                     action_size,\n",
    "                     buffer_size=2000,\n",
    "                     epsilon_start=0.5,\n",
    "                     epsilon_steps_to_min=3500,\n",
    "                     mode=\"DuelingDQN\",\n",
    "                     use_PER=True,\n",
    "                     pre_trained=pre_trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = \"logs/\" + time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "writer = tf.summary.create_file_writer(logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_EVERY_EPISODES = 100\n",
    "LEARNING_START_AFTER_STEPS = 500\n",
    "EPISODES = 80\n",
    "SCORE_TO_SOLVE = 195.0\n",
    "\n",
    "UPDATE_MODE = 'soft'\n",
    "UPDATE_TARGET_FREQUENCY = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started: 2019-12-29 13:29:18.235840\n",
      "Episode 1: Step 15 reward 15.0: \n",
      "Save model...\n",
      "Episode 5: Step 80 reward 30.0: \n",
      "Save model...\n",
      "Episode 6: Step 123 reward 43.0: \n",
      "Save model...\n",
      "Episode 7: Step 180 reward 57.0: \n",
      "Save model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Deep Learning\\Reinforcement-Learning\\OpenAI\\CartPole-v0\\memory.py:47: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  max_weight = (p_min * n) ** (-self.PER_b)\n",
      "D:\\Deep Learning\\Reinforcement-Learning\\OpenAI\\CartPole-v0\\memory.py:47: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  max_weight = (p_min * n) ** (-self.PER_b)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 46: Step 860 reward 58.0: \n",
      "Save model...\n",
      "Episode 47: Step 947 reward 87.0: \n",
      "Save model...\n",
      "Episode 61: Step 1757 reward 92.0: \n",
      "Save model...\n",
      "Episode 65: Step 2039 reward 105.0: \n",
      "Save model...\n",
      "Episode 67: Step 2269 reward 133.0: \n",
      "Save model...\n",
      "Episode 68: Step 2469 reward 200.0: \n",
      "Save model...\n",
      "Save model...\n",
      "Training finished\n"
     ]
    }
   ],
   "source": [
    "def train():\n",
    "    env = build_environment(seed=SEED)\n",
    "    agent = build_agent()\n",
    "    \n",
    "    max_reward = -9999999    \n",
    "    game_rewards_deque = deque(maxlen=100)    \n",
    "    frame_count = 0\n",
    "    \n",
    "    print(\"Training started: \" + str(datetime.datetime.now()))\n",
    "    \n",
    "    frame_count = 0\n",
    "    \n",
    "    for i_episode in range(1, EPISODES+1):\n",
    "        state = env.reset()\n",
    "            \n",
    "        game_reward = 0\n",
    "        steps = 0\n",
    "        \n",
    "        while True:\n",
    "            frame_count += 1\n",
    "            steps += 1\n",
    "            \n",
    "            state = agent.preprocess(state)                \n",
    "            action = agent.act(state)            \n",
    "            \n",
    "            next_state, reward, done, info = env.step(action)              \n",
    "            game_reward += reward\n",
    "        \n",
    "            agent.remember(state[0], action, reward, next_state, done)\n",
    "            \n",
    "            state = next_state\n",
    "            \n",
    "            if frame_count % 10000 == 0:\n",
    "                print(\"Step count: {}\".format(frame_count))\n",
    "            \n",
    "            if done:\n",
    "                break            \n",
    "            \n",
    "            if frame_count > LEARNING_START_AFTER_STEPS:                \n",
    "                agent.train()\n",
    "                if UPDATE_MODE == \"soft\":\n",
    "                    agent.soft_update_target_network()\n",
    "                \n",
    "            \n",
    "            if UPDATE_MODE == \"hard\" and frame_count % UPDATE_TARGET_FREQUENCY == 0:\n",
    "                agent.hard_update_target_network()\n",
    "    \n",
    "        # Log episode reward\n",
    "        with writer.as_default():\n",
    "            tf.summary.scalar(\"epsilon\", agent.epsilon, step=i_episode)\n",
    "            tf.summary.scalar(\"game_reward\", game_reward, step=i_episode)        \n",
    "            \n",
    "        if i_episode % SAVE_EVERY_EPISODES == 0:\n",
    "            print(\"Save after {} episodes.\".format(i_episode))\n",
    "            agent.save()             \n",
    "        \n",
    "        game_rewards_deque.append(game_reward)\n",
    "        \n",
    "        if game_reward > max_reward:\n",
    "            print(\"Episode {}: Step {} reward {}: \".format(i_episode, frame_count, game_reward))\n",
    "            max_reward = game_reward\n",
    "            agent.save()        \n",
    "        \n",
    "        if np.mean(game_rewards_deque) >= SCORE_TO_SOLVE:\n",
    "            agent.save()\n",
    "            print(\"Solved in Episode {} Step {} reward {}: \".format(i_episode, frame_count, game_reward))\n",
    "            break      \n",
    "    \n",
    "    env.close()\n",
    "    agent.save()\n",
    "   \n",
    "train()\n",
    "print(\"Training finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished with score: 161.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = build_environment(seed=SEED)\n",
    "agent = build_agent(pre_trained='model.h5')\n",
    "\n",
    "state = env.reset()\n",
    "final_reward = 0\n",
    "\n",
    "img = plt.imshow(env.render(mode='rgb_array'))\n",
    "while True:\n",
    "    img.set_data(env.render(mode='rgb_array'))\n",
    "    display.display(plt.gcf())\n",
    "    display.clear_output(wait=True)\n",
    "\n",
    "    state = np.reshape(state, [1, state_size])\n",
    "    action = agent.act(state)    \n",
    "    next_state, reward, done, info = env.step(action)\n",
    "    final_reward += reward \n",
    "    \n",
    "    state = next_state\n",
    "    \n",
    "    if done:\n",
    "        print(\"Episode finished with score: {}\".format(final_reward))\n",
    "        break\n",
    "env.close()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}